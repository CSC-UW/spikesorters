{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-cc3090d08fad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#from  RecordingExtractor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#from spikesorters import BaseSorter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasesorter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseSorter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msorter_tools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrecover_recording\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshellscript\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mShellScript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy.lib.format import open_memmap\n",
    "import sys\n",
    "import yaml\n",
    "\n",
    "import spikeextractors as se\n",
    "\n",
    "#from  RecordingExtractor\n",
    "#from spikesorters import BaseSorter\n",
    "from ..basesorter import BaseSorter\n",
    "from ..sorter_tools import recover_recording\n",
    "\n",
    "from ..utils.shellscript import ShellScript\n",
    "\n",
    "\n",
    "from shellscript import ShellScript\n",
    "\n",
    "try:\n",
    "    import yass\n",
    "    HAVE_YASS = True\n",
    "except ImportError:\n",
    "    HAVE_YASS = False\n",
    "\n",
    "print (\"HAVE_YASS: \", HAVE_YASS)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BaseSorter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-7d23b8b84de2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# yasssorter class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mYassSorter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseSorter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \"\"\" \n\u001b[1;32m      4\u001b[0m     \"\"\"\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'BaseSorter' is not defined"
     ]
    }
   ],
   "source": [
    "# yasssorter class\n",
    "class YassSorter(BaseSorter):\n",
    "    \"\"\" \n",
    "    \"\"\"\n",
    "\n",
    "    sorter_name = 'yass'\n",
    "    requires_locations = False\n",
    "    verbose = False\n",
    "    is_installed = HAVE_YASS\n",
    "\n",
    "    # _default_params comes from default Yass config.yaml file; \n",
    "    #  Should be autoloaded from yass_installation_directory/samples/10chan/config.yaml\n",
    "    #  - for now a copy is saved here: spikesorters/spikesorters/yass/config.yaml\n",
    "    \n",
    "#     _default_params = {\n",
    "#         'adjacency_radius': 100,  # Channel neighborhood adjacency radius corresponding to geom file\n",
    "#         'filter': True,\n",
    "#         }\n",
    "\n",
    "    # ALESSIO: Move thsi file locally to the yass directory;\n",
    "    default_config_fname = './config_sample.yaml'\n",
    "    with open(default_config_fname) as f:\n",
    "        _default_params = yaml.load(f, Loader=yaml.FullLoader)   \n",
    "    \n",
    "    _params_description = {\n",
    "        'data': \" ...\",\n",
    "    }\n",
    "\n",
    "    # \n",
    "    sorter_description = \"\"\"Yass uses Neural Networks and SuperResolution Deconvolution to sort Retinal and \n",
    "                        cortical data. \n",
    "                        For more information see https://www.biorxiv.org/content/10.1101/2020.03.18.997924v1\n",
    "                        \"\"\"\n",
    "\n",
    "    installation_mesg = \"\"\"\\nTo Install and Use Yass follow the wiki: \n",
    "                            https://github.com/paninski-lab/yass/wiki\n",
    "                        \"\"\"\n",
    "\n",
    "    def __init__(self, **kargs):\n",
    "        print (**kargs)\n",
    "        #BaseSorter.__init__(self, rec, output_folder)\n",
    "        self.params = self._default_params\n",
    "        \n",
    "    @classmethod\n",
    "    def is_installed(cls):\n",
    "        #return HAVE_YASS\n",
    "        #return check_if_installed(cls.kilosort2_path)\n",
    "        return self.HAVE_YASS\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_sorter_version():\n",
    "        return yass.__version__\n",
    "\n",
    "    # NEED TO CHANGE THIS FOR YASS ALSO\n",
    "    # n_chan = recording.get_num_channels()\n",
    "    # n_frames = recording.get_num_frames()\n",
    "    # chunk_size = 2 ** 24 // n_chan\n",
    "    \n",
    "    # also make a default config file for\n",
    "    # https://github.com/SpikeInterface/spikesorters/blob/master/spikesorters/spyking_circus/config_default.params\n",
    "    # {} reserved for params that need to be updated at run time;\n",
    "    \n",
    "    # this function parses params and creates config file and binary data and geometry file also\n",
    "    # and saving everything to the output folder\n",
    "    # Cat: this function changes the minimum required default values; \n",
    "    def _setup_recording(self, recording, output_folder):\n",
    "        p = self.params\n",
    "        source_dir = Path(output_folder).parent\n",
    "\n",
    "        #################################################################\n",
    "        #################### UPDATE ROOT FOLDER #########################\n",
    "        #################################################################\n",
    "        # float(self._recording.sample_rate.rescale('Hz').magnitude)\n",
    "        self.params['data']['root_folder'] = output_folder\n",
    "        #self.params['data']['geometry'] = 'geom.csv'\n",
    "        \n",
    "        #################################################################\n",
    "        #################### GEOMETRY FILE GENERATION ###################\n",
    "        #################################################################\n",
    "        # save prb file\n",
    "        # note: only one group here, the split is done in basesorter\n",
    "        probe_file_csv = os.path.join(output_folder,'geom.csv')\n",
    "        probe_file_txt = os.path.join(output_folder,'geom.txt')\n",
    "        # ALESSIO .saveto probe saved .prb file; have to d thisourselves.\n",
    "        #  \n",
    "        adjacency_radius = -1\n",
    "        recording.save_to_probe_file(probe_file_csv, \n",
    "                                     grouping_property=None,\n",
    "                                     radius=adjacency_radius)\n",
    "        \n",
    "        import csv\n",
    "\n",
    "        with open(probe_file_csv) as csv_file:\n",
    "            csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "            geom_txt = np.float32(np.vstack(csv_reader))\n",
    "            np.savetxt(probe_file_txt, geom_txt)\n",
    "        \n",
    "        #################################################################\n",
    "        #################### UPDATE SAMPLING RATE #######################\n",
    "        #################################################################\n",
    "        # float(self._recording.sample_rate.rescale('Hz').magnitude)\n",
    "        self.params['recordings']['sampling_rate'] = recording.get_sampling_frequency()\n",
    "        \n",
    "        \n",
    "        #################################################################\n",
    "        #################### UPDATE N_CHAN  #############################\n",
    "        #################################################################\n",
    "        self.params['recordings']['n_channels'] = recording.get_num_channels()\n",
    "        \n",
    "        \n",
    "        #################################################################\n",
    "        #################### SAVE RAW INT16 data ########################\n",
    "        #################################################################\n",
    "        # ALESSIO Look at Kilosort \n",
    "        # There is alrady an extractor se.Mea1kRecordingExtractor()\n",
    "        # all the functions are there already to concatenate in time;\n",
    "        # multi-recording time extractor;\n",
    "        \n",
    "        # save binary file; THIS IS FROM KILOSORT\n",
    "        input_file_path = os.path.join(output_folder, 'data.bin')\n",
    "        \n",
    "        recording.write_to_binary_dat_format(input_file_path, \n",
    "                                             dtype='int16', \n",
    "                                             chunk_mb=500) # time_axis=0,1 for C/F order\n",
    "        \n",
    "        \n",
    "        #################################################################\n",
    "        #################### SAVE UPDATED CONFIG FILE ###################\n",
    "        #################################################################\n",
    "        fname_config = os.path.join(output_folder,\n",
    "                                   'config.yaml')\n",
    "        with open(fname_config, 'w') as file:\n",
    "            documents = yaml.dump(self.params, file)\n",
    "        \n",
    "        #self.fname_config = fname_config\n",
    "        \n",
    "        # ALESSIO:\n",
    "        # Expose more config file parameters that are sensiitive:\n",
    "        #  e.g. spike width; smallest cluster; min firing rates;\n",
    "        #  \n",
    "            \n",
    "    # FUNCTION TO RUN YASS \n",
    "    #def _run(self,recording, output_folder):  # SOMETIMES want to access more information from recording in\n",
    "                                               # this step\n",
    "    def _run(self, recording, output_folder):\n",
    "        '''\n",
    "        '''\n",
    "        recording = recover_recording(recording)  # allows this to run on multiple jobs (not just multi-core)\n",
    "        \n",
    "        if 'win' in sys.platform and sys.platform != 'darwin':\n",
    "            shell_cmd = '''\n",
    "                        yass sort {config}\n",
    "                    '''.format(config=os.path.join(output_folder,'config.yaml'))\n",
    "        else:\n",
    "            shell_cmd = '''\n",
    "                        #!/bin/bash\n",
    "                        yass sort {config}\n",
    "                    '''.format(config=os.path.join(output_folder,'config.yaml'))\n",
    "\n",
    "        shell_script = ShellScript(shell_cmd, \n",
    "                                   script_path=os.path.join(output_folder,self.sorter_name),\n",
    "                                   log_path=os.path.join(output_folder,self.sorter_name+'.log'), \n",
    "                                   verbose=self.verbose)\n",
    "        shell_script.start()\n",
    "\n",
    "        retcode = shell_script.wait()\n",
    "\n",
    "        if retcode != 0:\n",
    "            raise Exception('yass returned a non-zero exit code')\n",
    "    \n",
    "    # Alessio might not want to put here; \n",
    "    # better option to have a parameter \"tune_nn\" which \n",
    "    def train(self, recording, output_folder):\n",
    "        '''\n",
    "        '''\n",
    "        recording = recover_recording(recording)  # allows this to run on multiple jobs (not just multi-core)\n",
    "        \n",
    "        if 'win' in sys.platform and sys.platform != 'darwin':\n",
    "            shell_cmd = '''\n",
    "                        yass train {config}\n",
    "                    '''.format(config=os.path.join(output_folder,'config.yaml'))\n",
    "        else:\n",
    "            shell_cmd = '''\n",
    "                        #!/bin/bash\n",
    "                        yass train {config}\n",
    "                    '''.format(config=os.path.join(output_folder,'config.yaml'))\n",
    "\n",
    "        shell_script = ShellScript(shell_cmd, \n",
    "                                   script_path=os.path.join(output_folder,self.sorter_name),\n",
    "                                   log_path=os.path.join(output_folder,self.sorter_name+'.log'), \n",
    "                                   verbose=self.verbose)\n",
    "        shell_script.start()\n",
    "\n",
    "        retcode = shell_script.wait()\n",
    "\n",
    "        if retcode != 0:\n",
    "            raise Exception('yass returned a non-zero exit code')  \n",
    "            \n",
    "    def NNs_update(self):\n",
    "        ''' Update NNs to newly trained ones\n",
    "        '''\n",
    "        \n",
    "        #################################################################\n",
    "        #################### UPDATE CONFIG FILE TO NEW NNS ##############\n",
    "        #################################################################\n",
    "        self.params['neuralnetwork']['denoise']['filename']= os.path.join(\n",
    "                                            output_folder, \n",
    "                                            'tmp',\n",
    "                                            'nn_train',\n",
    "                                            'denoise.pt')\n",
    "        self.params['neuralnetwork']['detect']['filename']= os.path.join(\n",
    "                                            output_folder, \n",
    "                                            'tmp',\n",
    "                                            'nn_train',\n",
    "                                            'detect.pt')\n",
    "        \n",
    "        #################################################################\n",
    "        #################### SAVE UPDATED CONFIG FILE ###################\n",
    "        #################################################################\n",
    "        fname_config = os.path.join(output_folder,\n",
    "                                   'config.yaml')\n",
    "        \n",
    "        with open(fname_config, 'w') as file:\n",
    "            documents = yaml.dump(self.params, file)\n",
    "        \n",
    "        \n",
    "    def NNs_default(self):\n",
    "        ''' Revert to default NNs\n",
    "        '''\n",
    "        #################################################################\n",
    "        #################### UPDATE CONFIG FILE TO NEW NNS ##############\n",
    "        #################################################################\n",
    "        self.params['neuralnetwork']['denoise']['filename']= 'denoise.pt'\n",
    "        self.params['neuralnetwork']['detect']['filename']= 'detect.pt'\n",
    "        \n",
    "        #################################################################\n",
    "        #################### SAVE UPDATED CONFIG FILE ###################\n",
    "        #################################################################\n",
    "        fname_config = os.path.join(output_folder,\n",
    "                                   'config.yaml')\n",
    "        \n",
    "        with open(fname_config, 'w') as file:\n",
    "            documents = yaml.dump(self.params, file)        \n",
    "        \n",
    "    \n",
    "    # \n",
    "    @staticmethod\n",
    "    def get_result_from_folder(output_folder):\n",
    "        #sorting = se.YassSortingExtractor(folder_path=Path(output_folder) / 'tmp/output/spike_train.npy')\n",
    "        sorting = se.YassSortingExtractor(folder_path=Path(output_folder))\n",
    "        return sorting\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Yass Sorter\n",
    "sorter = YassSorter()\n",
    "print (\"yass installed: \", sorter.is_installed())\n",
    "print (\"yass version: \", sorter.get_sorter_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [2., 0.],\n",
       "       [3., 0.],\n",
       "       [4., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# INITIALIZE A TOY DATASET\n",
    "import spikeextractors as se\n",
    "rec, sort = se.example_datasets.toy_example(duration=300)\n",
    "rec.get_channel_locations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# INITIALIZE YASS SORTER OBJECT\n",
    "output_folder = '/media/cat/4TBSSD/spikeinterface/'\n",
    "sorter = YassSorter()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cat/.conda/envs/sf/lib/python3.7/site-packages/ipykernel_launcher.py:96: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n"
     ]
    }
   ],
   "source": [
    "# RUN SETUP\n",
    "sorter._setup_recording(rec, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING SHELL SCRIPT: /media/cat/4TBSSD/spikeinterface/yass.sh\n"
     ]
    }
   ],
   "source": [
    "# RUN TRAIN\n",
    "if False:\n",
    "    sorter.train(rec, output_folder)\n",
    "\n",
    "    # UPDATE NNs to TRAINED VERSIOn\n",
    "    sorter.NNs_update()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING SHELL SCRIPT: /media/cat/4TBSSD/spikeinterface/yass.sh\n"
     ]
    }
   ],
   "source": [
    "# RUN YASS\n",
    "sorter._run(rec, output_folder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unit:  3  spikes:  [ 27667  44270  44394  67223  68316  80673  82989  93560 109300 151074\n",
      " 179404 189923 200279 202184 203674 205694 276385 293983 304940 309969\n",
      " 310093 313842 330439 332320 366638 370371 395914]\n",
      "(8, 151, 4)\n"
     ]
    }
   ],
   "source": [
    "# VISUALIZE RESULTS\n",
    "from spikeextractors import YassSortingExtractor\n",
    "\n",
    "d = YassSortingExtractor(output_folder)\n",
    "\n",
    "unit_id = 3\n",
    "\n",
    "spikes = d.get_unit_spike_train(unit_id, start_frame=20000, end_frame=400000)\n",
    "print (\"Unit: \", unit_id, \" spikes: \", spikes)\n",
    "\n",
    "temps = d.get_temps()\n",
    "print (temps.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorter.run(rec, output_folder)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yass installed:  True\n",
      "yass version:  2.0\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EXTRACTOR THAT LOADS DEFAULT CONFIG FILE FOUND IN DATAFILE DIRECTORY\n",
    "# Default option is to send .bin binary file name and the geom.txt and config.yaml files to be hardcoded\n",
    "\n",
    "# initatlize extractor object\n",
    "extractor = YassDefaultRecordingExtractor('/home/cat/code/alessio/10chan/data.bin')\n",
    "extractor.get_channel_ids()\n",
    "extractor.get_geometry()\n",
    "extractor.get_num_frames()\n",
    "extractor.get_sampling_frequency()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING SHELL SCRIPT: /home/cat/code/alessio/10chan/yass.sh\n"
     ]
    }
   ],
   "source": [
    "output_folder = '/home/cat/code/alessio/10chan/'\n",
    "sorter._run(output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#se.YassSortingExtractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_unit_ids() missing 1 required positional argument: 'self'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-d0f69eb940fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mYassSortingExtractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_unit_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: get_unit_ids() missing 1 required positional argument: 'self'"
     ]
    }
   ],
   "source": [
    "temp = se.YassSortingExtractor.get_unit_ids()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print (temp.spike_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/cat/code/alessio/10chan/config.yaml\n"
     ]
    }
   ],
   "source": [
    "print (extractor.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# toy exapmle \n",
    "rec, sort = se.example_datasets.toy_example()\n",
    "print (rec.get_num_channels())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.params;  {'num_workers': 4}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'adjacency_radius'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-5aef2ee343d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0moutput_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/home/cat/code/alessio/10chan/tests/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m sorter._setup_recording(rec, \n\u001b[0;32m----> 4\u001b[0;31m                        output_folder)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-d0fa8e8c7123>\u001b[0m in \u001b[0;36m_setup_recording\u001b[0;34m(self, recording, output_folder)\u001b[0m\n\u001b[1;32m     90\u001b[0m         recording.save_to_probe_file(probe_file, \n\u001b[1;32m     91\u001b[0m                                      \u001b[0mgrouping_property\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m                                      radius=p['adjacency_radius'])\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;31m# save binary file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'adjacency_radius'"
     ]
    }
   ],
   "source": [
    "# output folder\n",
    "output_folder = '/home/cat/code/alessio/10chan/tests/'\n",
    "sorter._setup_recording(rec, \n",
    "                       output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'recording' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-3956946a191b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# alternative to get sorter extractor and run class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m sorter = YassSorter(recording=recording, output_folder=output_folder, grouping_property=grouping_property,\n\u001b[0m\u001b[1;32m      3\u001b[0m                          verbose=verbose, delete_output_folder=delete_output_folder)\n\u001b[1;32m      4\u001b[0m \u001b[0msorter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msorter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraise_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparallel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoblib_backend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjoblib_backend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'recording' is not defined"
     ]
    }
   ],
   "source": [
    "# alternative to get sorter extractor and run class\n",
    "sorter = YassSorter(recording=recording, output_folder=output_folder, grouping_property=grouping_property,\n",
    "                         verbose=verbose, delete_output_folder=delete_output_folder)\n",
    "sorter.set_params(**params)\n",
    "sorter.run(raise_error=raise_error, parallel=parallel, n_jobs=n_jobs, joblib_backend=joblib_backend)\n",
    "sortingextractor = sorter.get_result()\n",
    "\n",
    "#return sortingextractor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING SHELL SCRIPT: /home/cat/code/alessio/10chan/yass.sh\n"
     ]
    }
   ],
   "source": [
    "output_folder = '/home/cat/code/alessio/10chan/'\n",
    "\n",
    "sorter._run(extractor, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
